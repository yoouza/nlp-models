{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XOR.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMiIvz6KgbfkrwDSCNQ0pBK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoouza/nlp-models/blob/master/XOR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1j6j7uxMFgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.array([[0,0,1,1], [0,1,0,1]])\n",
        "Y = np.array([0,1,1,0])"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOjcJKyVJuwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1) 파라미터 초기화\n",
        "\n",
        "N_hidden = 2\n",
        "w_input = np.random.random_sample((len(X)+1, N_hidden))\n",
        "w_hidden = np.random.random_sample(N_hidden)\n",
        "w_b = np.random.random_sample()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDkOQxMeGhRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2) feed forward\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "b = np.ones(len(X[0]))\n",
        "X_b = np.concatenate([X, b.reshape(1, len(b))])\n",
        "\n",
        "h = sigmoid(np.dot(w_input.T, X_b))\n",
        "Y_hat = sigmoid(np.dot(w_hidden, h) + b * w_b)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL55-OzxY9D6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3) Loss\n",
        "\n",
        "N = len(Y)\n",
        "loss = (-1/N) * np.sum( np.multiply(Y, np.log(Y_hat)) + np.multiply( 1-Y, np.log(1-Y_hat) ) )"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5OYBmVXKnXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4) back-propagation\n",
        "\n",
        "# output -> hidden\n",
        "gradient_hidden = np.dot(h, Y_hat-Y)\n",
        "gradient_bias = Y_hat-Y\n",
        "\n",
        "# hidden -> input\n",
        "gradient_h = np.dot(w_hidden.reshape(len(w_hidden), 1), (Y_hat-Y).reshape(1, len(Y)))\n",
        "gradient_input = np.dot(X_b, np.multiply(gradient_h, h, 1-h).T)\n",
        "\n",
        "# update weights\n",
        "alpha = 0.01\n",
        "w_hidden = w_hidden - alpha * gradient_hidden\n",
        "b = b - alpha * gradient_bias\n",
        "w_input = w_input - alpha * gradient_input"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9O4kjXMY9KS",
        "colab_type": "text"
      },
      "source": [
        "# weight update 반복"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9A3ESKpQMSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_iter = 100000\n",
        "\n",
        "for iter in range(N_iter):\n",
        "    h = sigmoid(np.dot(w_input.T, X_b))\n",
        "    Y_hat = sigmoid(np.dot(w_hidden, h) + b * w_b)\n",
        "\n",
        "    loss = (-1/N) * np.sum( np.multiply(Y, np.log(Y_hat)) + np.multiply(1-Y, np.log(1-Y_hat)) )\n",
        "\n",
        "    # output -> hidden\n",
        "    gradient_hidden = np.dot(h, Y_hat-Y)\n",
        "    gradient_bias = Y_hat-Y\n",
        "\n",
        "    # hidden -> input\n",
        "    gradient_h = np.dot(w_hidden.reshape(len(w_hidden), 1), (Y_hat-Y).reshape(1, len(Y)))\n",
        "    gradient_input = np.dot(X_b, np.multiply(gradient_h, h, 1-h).T)\n",
        "\n",
        "    # update weights\n",
        "    w_hidden = w_hidden - alpha * gradient_hidden\n",
        "    b = b - alpha * gradient_bias\n",
        "    w_input = w_input - alpha * gradient_input"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXuW-s3GZtTq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11682cf0-f914-41c6-f175-85b8d224942a"
      },
      "source": [
        "Y_hat"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.12098237, 0.87995006, 0.88006595, 0.12087596])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzqMZOT45YrI",
        "colab_type": "text"
      },
      "source": [
        "# 클래스"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdgGzpzRU4oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class XOR:\n",
        "    def __init__(self, X, Y, N_hidden, alpha=.01):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.N_hidden = N_hidden\n",
        "        self.alpha = alpha\n",
        "        self.b = np.ones(len(X[0]))\n",
        "        self.X_b = np.concatenate([X, self.b.reshape(1, len(self.b))])\n",
        "        self.w_input = np.random.random_sample((len(X)+1, N_hidden))\n",
        "        self.w_hidden = np.random.random_sample(N_hidden)\n",
        "        self.w_b = np.random.random_sample()\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def train(self, N_iter):\n",
        "\n",
        "        N = len(self.Y)\n",
        "        for iter in range(N_iter):\n",
        "\n",
        "            h = self._sigmoid(np.dot(self.w_input.T, self.X_b))\n",
        "            Y_hat = self._sigmoid(np.dot(self.w_hidden, h) + self.b * self.w_b)\n",
        "            loss = (-1/N) * np.sum( np.multiply(self.Y, np.log(Y_hat)) + np.multiply(1-self.Y, np.log(1-Y_hat)) )\n",
        "\n",
        "            # output -> hidden\n",
        "            gradient_hidden = np.dot(h, Y_hat-self.Y)\n",
        "            gradient_bias = Y_hat-self.Y\n",
        "\n",
        "            # hidden -> input\n",
        "            gradient_h = np.dot(self.w_hidden.reshape(len(self.w_hidden), 1), (Y_hat-self.Y).reshape(1, N))\n",
        "            gradient_input = np.dot(self.X_b, np.multiply(gradient_h, h, 1-h).T)\n",
        "\n",
        "            # update weights\n",
        "            self.w_hidden = self.w_hidden - alpha * gradient_hidden\n",
        "            self.b = self.b - alpha * gradient_bias\n",
        "            self.w_input = self.w_input - alpha * gradient_input\n",
        "\n",
        "        return (Y_hat > 0.5) * 1, Y_hat"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqbTXHXX_EMm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8004e88c-4842-4864-c787-e34589a0f3c4"
      },
      "source": [
        "# example 1.\n",
        "\n",
        "xor = XOR(X, Y, N_hidden = 3)\n",
        "xor.train(N_iter = 10000)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 1, 0]), array([0.05416705, 0.94651544, 0.94677042, 0.05424499]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Natjz7lo-duF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ddb4f804-f49d-4a80-8772-3e10311dcfac"
      },
      "source": [
        "# example 2.\n",
        "\n",
        "xor = XOR(X, Y, N_hidden = 6)\n",
        "xor.train(N_iter = 1000)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 1, 0]), array([0.18704217, 0.82321839, 0.81688198, 0.17737163]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}