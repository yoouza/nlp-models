{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XOR.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMGH9ECP84K+tdtreFHsRo7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# XOR Gate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1j6j7uxMFgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.array([[0,0,1,1], [0,1,0,1]])\n",
        "Y = np.array([0,1,1,0])"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOjcJKyVJuwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1) 파라미터 초기화\n",
        "\n",
        "N_hidden = 2\n",
        "w_input = np.random.random_sample((len(X)+1, N_hidden))\n",
        "w_hidden = np.random.random_sample(N_hidden)\n",
        "w_b = np.random.random_sample()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDkOQxMeGhRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2) feed forward\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "b = np.ones(len(X[0]))\n",
        "X_b = np.concatenate([X, b.reshape(1, len(b))])\n",
        "\n",
        "h = sigmoid(np.dot(w_input.T, X_b))\n",
        "Y_hat = sigmoid(np.dot(w_hidden, h) + b * w_b)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL55-OzxY9D6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3) Loss\n",
        "\n",
        "N = len(Y)\n",
        "loss = (-1/N) * np.sum( np.multiply(Y, np.log(Y_hat)) + np.multiply( 1-Y, np.log(1-Y_hat) ) )"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5OYBmVXKnXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4) back-propagation\n",
        "\n",
        "# output -> hidden\n",
        "gradient_hidden = np.dot(h, Y_hat-Y)\n",
        "gradient_bias = Y_hat-Y\n",
        "\n",
        "# hidden -> input\n",
        "gradient_h = np.dot(w_hidden.reshape(len(w_hidden), 1), (Y_hat-Y).reshape(1, len(Y)))\n",
        "gradient_input = np.dot(X_b, np.multiply(gradient_h, h, 1-h).T)\n",
        "\n",
        "# update weights\n",
        "alpha = 0.01\n",
        "w_hidden = w_hidden - alpha * gradient_hidden\n",
        "b = b - alpha * gradient_bias\n",
        "w_input = w_input - alpha * gradient_input"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9O4kjXMY9KS",
        "colab_type": "text"
      },
      "source": [
        "# weight update 반복"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9A3ESKpQMSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_iter = 100000\n",
        "\n",
        "for iter in range(N_iter):\n",
        "    h = sigmoid(np.dot(w_input.T, X_b))\n",
        "    Y_hat = sigmoid(np.dot(w_hidden, h) + b * w_b)\n",
        "\n",
        "    loss = (-1/N) * np.sum( np.multiply(Y, np.log(Y_hat)) + np.multiply(1-Y, np.log(1-Y_hat)) )\n",
        "\n",
        "    # output -> hidden\n",
        "    gradient_hidden = np.dot(h, Y_hat-Y)\n",
        "    gradient_bias = Y_hat-Y\n",
        "\n",
        "    # hidden -> input\n",
        "    gradient_h = np.dot(w_hidden.reshape(len(w_hidden), 1), (Y_hat-Y).reshape(1, len(Y)))\n",
        "    gradient_input = np.dot(X_b, np.multiply(gradient_h, h, 1-h).T)\n",
        "\n",
        "    # update weights\n",
        "    w_hidden = w_hidden - alpha * gradient_hidden\n",
        "    b = b - alpha * gradient_bias\n",
        "    w_input = w_input - alpha * gradient_input"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXuW-s3GZtTq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11682cf0-f914-41c6-f175-85b8d224942a"
      },
      "source": [
        "Y_hat"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.12098237, 0.87995006, 0.88006595, 0.12087596])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzqMZOT45YrI",
        "colab_type": "text"
      },
      "source": [
        "# 클래스"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExnV_gVrl2v5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class XOR:    \n",
        "    def _init_weight(self, X, N_hidden):\n",
        "        w_input = np.random.random_sample((len(X)+1, N_hidden))\n",
        "        w_hidden = np.random.random_sample(N_hidden)\n",
        "        w_b = np.random.random_sample()\n",
        "        return w_input, w_hidden, w_b\n",
        "\n",
        "    def _loss(self, Y, Y_hat):\n",
        "        N = len(Y)\n",
        "        loss = (-1/N) * np.sum( np.multiply(Y, np.log(Y_hat)) + np.multiply(1-Y, np.log(1-Y_hat)) )\n",
        "        return loss\n",
        "    \n",
        "    def _sigmoid(self, v):\n",
        "        return 1 / (1 + np.exp(-v))\n",
        "\n",
        "    def optimize(self, X, Y, N_hidden, alpha, epoch):\n",
        "        \n",
        "        w_input, w_hidden, w_b = self._init_weight(X, N_hidden)\n",
        "\n",
        "        b = np.ones(len(X[0]))\n",
        "        X_b = np.concatenate([X, b.reshape(1, len(b))])\n",
        "\n",
        "        for i in range(epoch):\n",
        "            h = self._sigmoid(np.dot(w_input.T, X_b))\n",
        "            Y_hat = self._sigmoid(np.dot(w_hidden, h) + b * w_b)\n",
        "            loss = self._loss(Y, Y_hat)\n",
        "\n",
        "            # output -> hidden\n",
        "            gradient_hidden = np.dot(h, Y_hat-Y)\n",
        "            gradient_bias = Y_hat-Y\n",
        "\n",
        "            # hidden -> input\n",
        "            gradient_h = np.dot(w_hidden.reshape(len(w_hidden), 1), (Y_hat-Y).reshape(1, N))\n",
        "            gradient_input = np.dot(X_b, np.multiply(gradient_h, h, 1-h).T)\n",
        "\n",
        "            # update weights\n",
        "            w_hidden = w_hidden - alpha * gradient_hidden\n",
        "            b = b - alpha * gradient_bias\n",
        "            w_input = w_input - alpha * gradient_input\n",
        "\n",
        "        return (Y_hat > 0.5) * 1, Y_hat"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj9kx4Ahl3KI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "247a8301-f8f0-463a-8e45-ada972025cbd"
      },
      "source": [
        "xor = XOR()\n",
        "pred, y_hat = xor.optimize(X, Y, 5, alpha = .01, epoch = 10000)\n",
        "print('pred:', pred)\n",
        "print('y_hat:', y_hat)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pred: [0 1 1 0]\n",
            "y_hat: [0.02873412 0.97197709 0.97162749 0.02841604]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}